---
layout: post
title:  "Leveraging The CramÃ©r-Rao Lower Bound For Navigation"
categories: [Navigation]
tags: [blog,tech,navigation,estimation,theory,sensorfusion]
image:
  path: /media/crlb/Cramer-Rao Lower Bound.png
  alt: Leveraging The CramÃ©r-Rao Lower Bound For Navigation
---

# $Var(Î¸) â‰¥ \frac{1}{E[(\frac{âˆ‚ ln f(x; Î¸)}{âˆ‚Î¸})Â²]}$

If that doesn't attract your attention, I don't know what will!

Jokes aside, what you see there is something incredibly intuitive and useful for us navigation folks.  

## What is it?  
It is the **Cramer-Rao Lower Bound (CRLB)**. Sounds just as exciting as that equation above, right? Well, it actually is!

The CRLB provides a **theoretical limit on the variance of an unbiased** estimator, offering a benchmark to assess the performance of estimation algorithms. In navigation, it can be applied to analyze position, velocity, and attitude estimation. Here's why itâ€™s so powerful:

### Performance Benchmarking  
By comparing an algorithmâ€™s error variance to the CRLB, we can identify how close the system is to achieving optimal accuracy.

> Optimal accuracy doesnâ€™t mean the estimate perfectly matches the ground truthâ€”it means achieving the **minimum variance** given the available data. This occurs when the estimator effectively utilizes all the information present in the data.  
{: .prompt-tip}

### Sensor Design Insights  
The CRLB helps guide the integration of sensors by quantifying how additional measurements (e.g., accelerometers, gyroscopes, or external beacons) improve estimation precision. 

### System Optimization  
It allows engineers to adjust factors such as measurement update rates, noise characteristics, and filtering parameters for enhanced performance.  

For example, in **GPS-denied environments** where inertial navigation plays a critical role, the CRLB can show how multi-sensor fusion (e.g., using LiDAR or vision) impacts navigation accuracy. Furthermore, it can help evaluate if the fusion algorithm makes efficient use of the available data Itâ€™s an invaluable tool for making data-driven design decisions and evaluating estimation models.  

Letâ€™s break it down a bit more!

## The Formula 

Let's take a look at the intuitive nature behind this formula, which might seem a bit intricate at first glance. The CRLB delivers the minimum variance an unbiased estimator can achieve. To achieve the smallest variance, we want the denominator of this fraction to be as large as possible.
So, what is this denominator?

Itâ€™s called the **Fisher Information**. 

### Fisher Information

The Fisher Information captures how much information our sensor data carries about the parameter we want to estimate, Î¸.

Imagine you have a clear, sharp photo of a car. You want to estimate its position based on the image. Because the photo is clear, you can point your finger right at the car and be pretty confident about its location. On the other hand, if the picture is motion blurred, you can only make a rough guess about where the car might be.

This is where Fisher information comes in: In the sharp picture, the likelihood of the car being in any one spot is very high, and the likelihood drops significantly if you move your finger just a little bit. This means the Fisher information is high because the likelihood changes sharply. In the blurry picture, the car could pretty much be anywhere within that blur! The likelihood doesnâ€™t change much if you move your finger left or right. The uncertainty about the carâ€™s location is high, and so the Fisher information is low.

How does this relate to variance?

In the sharp picture, because the Fisher information is high, the variance of our estimate is low. We know the carâ€™s location with high precision. On the blurry picture, with low Fisher information, the variance is high. Our estimate of the carâ€™s position is more uncertain.

## Practical Use

In practice, this idea can help us figure out if adding a new sensor will actually improve our estimates.

For example: Adding a new camera could help, but only if it gives us meaningful new information (like if itâ€™s actually pointed in the right direction!) Or, maybe itâ€™s better to add odometry data for better accuracy? The CRLB helps us determine if the new sensor setup will make a real difference, and whether the quality is good enough to improve our estimates.

So, the next time you consider adding a sensor to improve accuracy, think about the CRLB! ðŸ˜Ž