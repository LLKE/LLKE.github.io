---
layout: post
title:  "Leveraging The CramÃ©r-Rao Lower Bound For Navigation"
categories: [Navigation]
tags: [blog,tech,navigation,estimation,theory,sensorfusion]
image:
  path: /media/crlb/Cramer-Rao Lower Bound.png
  alt: Leveraging The CramÃ©r-Rao Lower Bound For Navigation
---


## â— The Formula
**Var(Î¸) â‰¥ 1 / E[(âˆ‚ ln f(x; Î¸) / âˆ‚Î¸)Â²]**

ğŸ‘€ Did I catch your attention?

I sure hope I did because what you see there is actually something very intuitive and useful for us navigation folks.

## â“ What is the CramÃ©r-Rao Lower Bound?

The CRLB provides a theoretical limit on the variance of an unbiased estimator, offering a benchmark to assess the performance of estimation algorithms. In navigation, it can be applied to analyze position, velocity, and attitude estimation. Here's why itâ€™s so powerful:

## ğŸ¤“ What is it Good For?
**1ï¸âƒ£ Performance Benchmarking**

By comparing an algorithmâ€™s error variance to the CRLB, we can identify how close the system is to achieving optimal accuracy.

> Note: Optimal accuracy does not mean that > the estimate perfectly matches ground truth, only that it achieves the minimum variance given the data we have. This occurs if the estimator uses all available information that can be gained from the data.
{: .prompt-tip }

**2ï¸âƒ£ Sensor Design Insights**

The CRLB helps guide the integration of sensors by quantifying how additional measurements (e.g., accelerometers, gyroscopes, or external beacons) improve estimation precision.

**3ï¸âƒ£ System Optimization**

It allows engineers to adjust factors such as measurement update rates, noise characteristics, and filtering parameters for enhanced performance.
For example, in GPS-denied environments where inertial navigation plays a critical role, the CRLB can show how multi-sensor fusion (e.g., using LiDAR or vision) impacts navigation accuracy. 
Furthermore, it can help evaluate if the fusion algorithm makes efficient use of the available data. ğŸ§­ Itâ€™s an invaluable tool for making data-driven design decisions and evaluating estimation models.

ğŸ’­ I had heard of the CRLB often during my studies and never really understood it. I only recently learned about it in the context of navigation. Now, it actually makes sense, and I plan to make good use of it!

## ğŸ” Let's Break it down

ğŸ’¡ Let's explore the intuitive nature behind this formula, which might seem a bit intricate at first glance.

The CRLB delivers the minimum variance an unbiased estimator can achieve.
To achieve the smallest variance, we want the denominator of this fraction to be as large as possible.

**â“ So, what is this denominator?**

ğŸ” Itâ€™s called the **Fisher Information**.

The Fisher Information captures how much information our sensor data carries about the parameter we want to estimate, Î¸.

ğŸ“¸ Imagine you have a clear, sharp photo of a car. You want to estimate its position based on the image.

+ Because the photo is clear, you can point your finger right at the car and be pretty confident about its location.
+ On the other hand, if the picture is motion blurred, you can only make a rough guess about where the car might be.

âš¡ This is where Fisher information comes in:

+ In the sharp picture, the likelihood of the car being in any one spot is very high, and the likelihood drops significantly if you move your finger just a little bit. This means the Fisher information is high because the likelihood changes sharply.
+ In the blurry picture, the car could pretty much be anywhere within that blur! The likelihood doesnâ€™t change much if you move your finger left or right. The uncertainty about the carâ€™s location is high, and so the Fisher information is low.

**ğŸ“Š How does this relate to variance?**

+ In the sharp picture, because the Fisher information is high, the variance of our estimate is low. We know the carâ€™s location with high precision.
+ In the blurry picture, with low Fisher information, the variance is high. Our estimate of the carâ€™s position is more uncertain.

## ğŸ› ï¸ A Practical Perspective

ğŸ“ˆ This idea can help us figure out if adding a new sensor will actually improve our estimates.

For example:

+ Adding a new camera could help, but only if it gives us meaningful new information (like if itâ€™s actually pointed in the right direction!).
+ Or, maybe itâ€™s better to add odometry data for better accuracy? ğŸ¤”

The CRLB helps us determine if the new sensor setup will make a real difference and whether the quality is good enough to improve our estimates.

ğŸ’¡ So, the next time you consider adding a sensor to improve accuracy, think about the CRLB! ğŸ˜
